{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18da0ba",
   "metadata": {},
   "source": [
    "# torchtext 튜토리얼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16444ce1",
   "metadata": {},
   "source": [
    "## 샘플 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e1ecbacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"Western Union\" is something of a forgotten cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>This movie is an incredible piece of work. It ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>My wife and I watched this movie because we pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>When I first watched Flatliners, I was amazed....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>Why would this film be so good, but only gross...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I grew up (b. 1965) watching and loving the Th...      0\n",
       "1      When I put this movie in my DVD player, and sa...      0\n",
       "2      Why do people who do not know what a particula...      0\n",
       "3      Even though I have great interest in Biblical ...      0\n",
       "4      Im a die hard Dads Army fan and nothing will e...      1\n",
       "...                                                  ...    ...\n",
       "39995  \"Western Union\" is something of a forgotten cl...      1\n",
       "39996  This movie is an incredible piece of work. It ...      1\n",
       "39997  My wife and I watched this movie because we pl...      0\n",
       "39998  When I first watched Flatliners, I was amazed....      1\n",
       "39999  Why would this film be so good, but only gross...      1\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('movie.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd4e1f6",
   "metadata": {},
   "source": [
    "## 토크나이저 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1eb7416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55cac9c",
   "metadata": {},
   "source": [
    "tokenizer의 타입으로는 `basic_english`, `spacy`, `moses`, `toktok`, `revtok`, `subword` 이 있습니다.\n",
    "\n",
    "다만, 이 중 몇개의 타입은 추가 패키지가 설치되어야 정상 동작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2b9635d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', \"'\", 'd', 'like', 'to', 'learn', 'torchtext']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english', language='en')\n",
    "tokenizer(\"I'd like to learn torchtext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ca85a",
   "metadata": {},
   "source": [
    "토큰 타입을 지정하면 그에 맞는 tokenizer를 반환하는 함수를 생성한 뒤 원하는 타입을 지정하여 tokenizer를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d3e0dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokenizer(tokenizer_type, language='en'):\n",
    "    return get_tokenizer(tokenizer_type, language=language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4b4e0",
   "metadata": {},
   "source": [
    "`basic_english`를 적용한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e42fb933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', \"'\", 'd', 'like', 'to', 'learn', 'torchtext']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = generate_tokenizer('basic_english')\n",
    "tokenizer(\"I'd like to learn torchtext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f79eaf1",
   "metadata": {},
   "source": [
    "`toktok`을 적용한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6c58dac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'\", 'd', 'like', 'to', 'learn', 'torchtext']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = generate_tokenizer('toktok')\n",
    "tokenizer(\"I'd like to learn torchtext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ae2c6d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'d\", 'like', 'to', 'learn', 'torchtext']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(\"I'd like to learn torchtext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b58397",
   "metadata": {},
   "source": [
    "## 필드(Field) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a82326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93659a49",
   "metadata": {},
   "source": [
    "`torchtext.legacy.data.Field` \n",
    "- `Field` 클래스는 `Tensor`로 변환하기 위한 지침과 함께 데이터 유형을 정의합니다. \n",
    "- `Field` 객체는 `vocab` 개체를 보유합니다.\n",
    "- `Field` 객체는 토큰화 방법, 생성할 Tensor 종류와 같이 데이터 유형을 수치화하는 역할을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "faf5b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,    # 순서를 반영\n",
    "                  tokenize=tokenizer, # tokenizer 지정\n",
    "                  fix_length=120,     # 한 문장의 최대 길이 지정\n",
    "                  lower=True,         # 소문자 화\n",
    "                  batch_first=True)   # batch 를 가장 먼저 출력\n",
    "\n",
    "\n",
    "LABEL = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae60ee06",
   "metadata": {},
   "source": [
    "`fields` 변수에 dictionary를 생성합니다.\n",
    "- `key`: 읽어 들여올 파일의 열 이름을 지정합니다.\n",
    "- `value`: (`문자열`, `data.Field`) 형식으로 지정합니다. 여기서 지정한 문자열이 나중에 생성된 data의 변수 이름으로 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0cf04c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('text', TEXT), \n",
    "          ('label', LABEL)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920e0d0",
   "metadata": {},
   "source": [
    "## 데이터셋 로드 및 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d3b98",
   "metadata": {},
   "source": [
    "`TabularDataset` 클래스는 정형 데이터파일로부터 직접 데이터를 읽을 때 유용합니다.\n",
    "\n",
    "지원하는 파일 형식은 `CSV`, `JSON`, `TSV` 을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3bbb6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "dataset = TabularDataset(path='movie.csv',  # 파일의 경로\n",
    "                         format='CSV',         # 형식 지정\n",
    "                         fields=fields,  # 이전에 생성한 field 지정\n",
    "                         skip_header=True\n",
    "                        )        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a817a3b",
   "metadata": {},
   "source": [
    "이전에 생성한 `dataset` 변수로 train / test 데이터셋을 분할 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5c0b5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = dataset.split(split_ratio=0.8,               # 분할 비율\n",
    "                                      stratified=True,               # stratify 여부\n",
    "                                      strata_field='label',          # stratify 대상 컬럼명\n",
    "                                      random_state=random.seed(SEED) # 시드\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "800199d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 8000)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 train / test 데이터셋의 크기를 출력 합니다.\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12a8f3",
   "metadata": {},
   "source": [
    "## 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ddba3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, \n",
    "                 max_size=2000,  # 최대 vocab_size 지정\n",
    "                 min_freq=5,     # 최소 빈도 단어수 지정\n",
    "                 vectors='glove.6B.100d')   # 워드임베딩 vector 지정, None으로 지정시 vector 사용 안함\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5c89b7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_VOCABS = len(TEXT.vocab.stoi)\n",
    "NUM_VOCABS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2b574",
   "metadata": {},
   "source": [
    "`TEXT.vocab.stoi`는 문자열을 index로, `TEXT.vocab.itos`는 index를 문자열로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "08c0c78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7f588d30b370>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'the': 2,\n",
       "             ',': 3,\n",
       "             'and': 4,\n",
       "             'a': 5,\n",
       "             'of': 6,\n",
       "             'to': 7,\n",
       "             \"'\": 8,\n",
       "             'is': 9,\n",
       "             '/': 10,\n",
       "             'in': 11,\n",
       "             'it': 12,\n",
       "             'i': 13,\n",
       "             'this': 14,\n",
       "             'that': 15,\n",
       "             '\"': 16,\n",
       "             's': 17,\n",
       "             '><br': 18,\n",
       "             'was': 19,\n",
       "             'as': 20,\n",
       "             'for': 21,\n",
       "             'with': 22,\n",
       "             'but': 23,\n",
       "             'movie': 24,\n",
       "             ')': 25,\n",
       "             'film': 26,\n",
       "             'you': 27,\n",
       "             't': 28,\n",
       "             'on': 29,\n",
       "             '(': 30,\n",
       "             'not': 31,\n",
       "             'are': 32,\n",
       "             'he': 33,\n",
       "             'his': 34,\n",
       "             '.': 35,\n",
       "             'have': 36,\n",
       "             'be': 37,\n",
       "             '!': 38,\n",
       "             'one': 39,\n",
       "             'at': 40,\n",
       "             'they': 41,\n",
       "             'by': 42,\n",
       "             'all': 43,\n",
       "             'an': 44,\n",
       "             'who': 45,\n",
       "             'from': 46,\n",
       "             'like': 47,\n",
       "             'so': 48,\n",
       "             'or': 49,\n",
       "             'just': 50,\n",
       "             'there': 51,\n",
       "             'about': 52,\n",
       "             'has': 53,\n",
       "             'her': 54,\n",
       "             'if': 55,\n",
       "             'out': 56,\n",
       "             'what': 57,\n",
       "             'some': 58,\n",
       "             'can': 59,\n",
       "             '?': 60,\n",
       "             'very': 61,\n",
       "             'good': 62,\n",
       "             'when': 63,\n",
       "             'more': 64,\n",
       "             'she': 65,\n",
       "             'even': 66,\n",
       "             'would': 67,\n",
       "             'no': 68,\n",
       "             'my': 69,\n",
       "             'which': 70,\n",
       "             'up': 71,\n",
       "             'only': 72,\n",
       "             'really': 73,\n",
       "             'their': 74,\n",
       "             'see': 75,\n",
       "             'had': 76,\n",
       "             'were': 77,\n",
       "             'we': 78,\n",
       "             'story': 79,\n",
       "             'time': 80,\n",
       "             '<br': 81,\n",
       "             ':': 82,\n",
       "             '...': 83,\n",
       "             'than': 84,\n",
       "             'me': 85,\n",
       "             '-': 86,\n",
       "             'get': 87,\n",
       "             'much': 88,\n",
       "             'will': 89,\n",
       "             'been': 90,\n",
       "             'into': 91,\n",
       "             'because': 92,\n",
       "             'also': 93,\n",
       "             'other': 94,\n",
       "             'how': 95,\n",
       "             'do': 96,\n",
       "             'great': 97,\n",
       "             'don': 98,\n",
       "             'people': 99,\n",
       "             'most': 100,\n",
       "             'well': 101,\n",
       "             'first': 102,\n",
       "             'bad': 103,\n",
       "             'its': 104,\n",
       "             'could': 105,\n",
       "             'then': 106,\n",
       "             'make': 107,\n",
       "             'any': 108,\n",
       "             '>the': 109,\n",
       "             'him': 110,\n",
       "             'made': 111,\n",
       "             'after': 112,\n",
       "             'think': 113,\n",
       "             'too': 114,\n",
       "             'way': 115,\n",
       "             ';': 116,\n",
       "             'them': 117,\n",
       "             'many': 118,\n",
       "             'movies': 119,\n",
       "             'characters': 120,\n",
       "             'being': 121,\n",
       "             'never': 122,\n",
       "             'character': 123,\n",
       "             'two': 124,\n",
       "             'where': 125,\n",
       "             'watch': 126,\n",
       "             'little': 127,\n",
       "             'love': 128,\n",
       "             'know': 129,\n",
       "             'films': 130,\n",
       "             'seen': 131,\n",
       "             'did': 132,\n",
       "             'acting': 133,\n",
       "             'best': 134,\n",
       "             'plot': 135,\n",
       "             'your': 136,\n",
       "             'ever': 137,\n",
       "             'does': 138,\n",
       "             'show': 139,\n",
       "             'still': 140,\n",
       "             'these': 141,\n",
       "             'say': 142,\n",
       "             'man': 143,\n",
       "             'over': 144,\n",
       "             'off': 145,\n",
       "             'better': 146,\n",
       "             've': 147,\n",
       "             'life': 148,\n",
       "             'it.': 149,\n",
       "             'why': 150,\n",
       "             'movie.': 151,\n",
       "             'scene': 152,\n",
       "             'such': 153,\n",
       "             'should': 154,\n",
       "             'while': 155,\n",
       "             'm': 156,\n",
       "             'something': 157,\n",
       "             'those': 158,\n",
       "             'go': 159,\n",
       "             'scenes': 160,\n",
       "             'end': 161,\n",
       "             '--': 162,\n",
       "             'through': 163,\n",
       "             'here': 164,\n",
       "             'doesn': 165,\n",
       "             'real': 166,\n",
       "             'back': 167,\n",
       "             'didn': 168,\n",
       "             '>i': 169,\n",
       "             'watching': 170,\n",
       "             'thing': 171,\n",
       "             'actually': 172,\n",
       "             'makes': 173,\n",
       "             'find': 174,\n",
       "             'look': 175,\n",
       "             'film.': 176,\n",
       "             'actors': 177,\n",
       "             'though': 178,\n",
       "             'now': 179,\n",
       "             'every': 180,\n",
       "             'going': 181,\n",
       "             'few': 182,\n",
       "             'new': 183,\n",
       "             'same': 184,\n",
       "             'lot': 185,\n",
       "             'nothing': 186,\n",
       "             'years': 187,\n",
       "             'another': 188,\n",
       "             'before': 189,\n",
       "             're': 190,\n",
       "             'old': 191,\n",
       "             'director': 192,\n",
       "             'quite': 193,\n",
       "             'pretty': 194,\n",
       "             'part': 195,\n",
       "             'want': 196,\n",
       "             'seems': 197,\n",
       "             'funny': 198,\n",
       "             'young': 199,\n",
       "             'us': 200,\n",
       "             'work': 201,\n",
       "             '&amp;': 202,\n",
       "             'got': 203,\n",
       "             'things': 204,\n",
       "             'big': 205,\n",
       "             'give': 206,\n",
       "             'fact': 207,\n",
       "             'take': 208,\n",
       "             'around': 209,\n",
       "             'cast': 210,\n",
       "             'thought': 211,\n",
       "             'down': 212,\n",
       "             'horror': 213,\n",
       "             'both': 214,\n",
       "             'may': 215,\n",
       "             'enough': 216,\n",
       "             'between': 217,\n",
       "             'world': 218,\n",
       "             'without': 219,\n",
       "             'always': 220,\n",
       "             'however': 221,\n",
       "             'isn': 222,\n",
       "             'almost': 223,\n",
       "             'must': 224,\n",
       "             'saw': 225,\n",
       "             'gets': 226,\n",
       "             'again': 227,\n",
       "             'whole': 228,\n",
       "             'come': 229,\n",
       "             'long': 230,\n",
       "             'least': 231,\n",
       "             'own': 232,\n",
       "             'guy': 233,\n",
       "             'music': 234,\n",
       "             'll': 235,\n",
       "             'might': 236,\n",
       "             'original': 237,\n",
       "             'bit': 238,\n",
       "             'probably': 239,\n",
       "             'last': 240,\n",
       "             'right': 241,\n",
       "             'far': 242,\n",
       "             'am': 243,\n",
       "             'series': 244,\n",
       "             'interesting': 245,\n",
       "             'action': 246,\n",
       "             'point': 247,\n",
       "             'feel': 248,\n",
       "             'anything': 249,\n",
       "             'since': 250,\n",
       "             'comedy': 251,\n",
       "             'kind': 252,\n",
       "             'times': 253,\n",
       "             'done': 254,\n",
       "             'role': 255,\n",
       "             'family': 256,\n",
       "             'd': 257,\n",
       "             'rather': 258,\n",
       "             'script': 259,\n",
       "             'worst': 260,\n",
       "             'yet': 261,\n",
       "             'played': 262,\n",
       "             'each': 263,\n",
       "             'anyone': 264,\n",
       "             'minutes': 265,\n",
       "             'found': 266,\n",
       "             'especially': 267,\n",
       "             'woman': 268,\n",
       "             'our': 269,\n",
       "             'girl': 270,\n",
       "             'sure': 271,\n",
       "             'tv': 272,\n",
       "             'making': 273,\n",
       "             'comes': 274,\n",
       "             'believe': 275,\n",
       "             'performance': 276,\n",
       "             'trying': 277,\n",
       "             'away': 278,\n",
       "             'having': 279,\n",
       "             'course': 280,\n",
       "             'although': 281,\n",
       "             'goes': 282,\n",
       "             'put': 283,\n",
       "             'hard': 284,\n",
       "             'fun': 285,\n",
       "             'main': 286,\n",
       "             '>this': 287,\n",
       "             'wasn': 288,\n",
       "             'worth': 289,\n",
       "             'maybe': 290,\n",
       "             'looking': 291,\n",
       "             'looks': 292,\n",
       "             'let': 293,\n",
       "             'three': 294,\n",
       "             'during': 295,\n",
       "             'everything': 296,\n",
       "             'shows': 297,\n",
       "             'watched': 298,\n",
       "             'seem': 299,\n",
       "             'someone': 300,\n",
       "             'different': 301,\n",
       "             'plays': 302,\n",
       "             'set': 303,\n",
       "             'everyone': 304,\n",
       "             'once': 305,\n",
       "             'takes': 306,\n",
       "             'true': 307,\n",
       "             'day': 308,\n",
       "             'play': 309,\n",
       "             'reason': 310,\n",
       "             'dvd': 311,\n",
       "             'actor': 312,\n",
       "             'american': 313,\n",
       "             'said': 314,\n",
       "             'seeing': 315,\n",
       "             'john': 316,\n",
       "             'left': 317,\n",
       "             'ending': 318,\n",
       "             'effects': 319,\n",
       "             'special': 320,\n",
       "             '2': 321,\n",
       "             'instead': 322,\n",
       "             'place': 323,\n",
       "             'book': 324,\n",
       "             'sense': 325,\n",
       "             'beautiful': 326,\n",
       "             'black': 327,\n",
       "             'later': 328,\n",
       "             '10': 329,\n",
       "             'money': 330,\n",
       "             'job': 331,\n",
       "             'simply': 332,\n",
       "             'high': 333,\n",
       "             '.<br': 334,\n",
       "             'read': 335,\n",
       "             'fan': 336,\n",
       "             'used': 337,\n",
       "             'war': 338,\n",
       "             'completely': 339,\n",
       "             'screen': 340,\n",
       "             'shot': 341,\n",
       "             'idea': 342,\n",
       "             'nice': 343,\n",
       "             'night': 344,\n",
       "             'audience': 345,\n",
       "             'excellent': 346,\n",
       "             'himself': 347,\n",
       "             'together': 348,\n",
       "             'short': 349,\n",
       "             'version': 350,\n",
       "             'poor': 351,\n",
       "             'time.': 352,\n",
       "             'try': 353,\n",
       "             'along': 354,\n",
       "             'wife': 355,\n",
       "             'until': 356,\n",
       "             'second': 357,\n",
       "             'given': 358,\n",
       "             'house': 359,\n",
       "             'truly': 360,\n",
       "             'men': 361,\n",
       "             'half': 362,\n",
       "             'need': 363,\n",
       "             'help': 364,\n",
       "             'father': 365,\n",
       "             'use': 366,\n",
       "             'kids': 367,\n",
       "             'less': 368,\n",
       "             'star': 369,\n",
       "             'else': 370,\n",
       "             'enjoy': 371,\n",
       "             'rest': 372,\n",
       "             'couple': 373,\n",
       "             'recommend': 374,\n",
       "             '..': 375,\n",
       "             'getting': 376,\n",
       "             'full': 377,\n",
       "             'death': 378,\n",
       "             '>': 379,\n",
       "             'year': 380,\n",
       "             'won': 381,\n",
       "             'came': 382,\n",
       "             'keep': 383,\n",
       "             'tell': 384,\n",
       "             'remember': 385,\n",
       "             'women': 386,\n",
       "             'friends': 387,\n",
       "             'hollywood': 388,\n",
       "             'dead': 389,\n",
       "             'mean': 390,\n",
       "             'home': 391,\n",
       "             'understand': 392,\n",
       "             'definitely': 393,\n",
       "             '>it': 394,\n",
       "             'mind': 395,\n",
       "             'playing': 396,\n",
       "             'small': 397,\n",
       "             'start': 398,\n",
       "             'early': 399,\n",
       "             'classic': 400,\n",
       "             'perhaps': 401,\n",
       "             'production': 402,\n",
       "             'performances': 403,\n",
       "             'human': 404,\n",
       "             'sex': 405,\n",
       "             'line': 406,\n",
       "             'next': 407,\n",
       "             'certainly': 408,\n",
       "             'boring': 409,\n",
       "             'doing': 410,\n",
       "             'gives': 411,\n",
       "             'couldn': 412,\n",
       "             'school': 413,\n",
       "             'stupid': 414,\n",
       "             'piece': 415,\n",
       "             'wonderful': 416,\n",
       "             'absolutely': 417,\n",
       "             'went': 418,\n",
       "             'liked': 419,\n",
       "             'often': 420,\n",
       "             'entire': 421,\n",
       "             'name': 422,\n",
       "             'sort': 423,\n",
       "             'felt': 424,\n",
       "             'top': 425,\n",
       "             'loved': 426,\n",
       "             'perfect': 427,\n",
       "             'video': 428,\n",
       "             'person': 429,\n",
       "             'several': 430,\n",
       "             'camera': 431,\n",
       "             'supposed': 432,\n",
       "             'become': 433,\n",
       "             'mother': 434,\n",
       "             'moments': 435,\n",
       "             'budget': 436,\n",
       "             'either': 437,\n",
       "             'boy': 438,\n",
       "             'seemed': 439,\n",
       "             'hope': 440,\n",
       "             'live': 441,\n",
       "             'lost': 442,\n",
       "             'wrong': 443,\n",
       "             'lines': 444,\n",
       "             'itself': 445,\n",
       "             'episode': 446,\n",
       "             'face': 447,\n",
       "             'totally': 448,\n",
       "             'written': 449,\n",
       "             'terrible': 450,\n",
       "             'against': 451,\n",
       "             'children': 452,\n",
       "             'case': 453,\n",
       "             'awful': 454,\n",
       "             'finally': 455,\n",
       "             'wanted': 456,\n",
       "             'head': 457,\n",
       "             'stars': 458,\n",
       "             'waste': 459,\n",
       "             'friend': 460,\n",
       "             'final': 461,\n",
       "             'others': 462,\n",
       "             'sound': 463,\n",
       "             'dialogue': 464,\n",
       "             'yes': 465,\n",
       "             'becomes': 466,\n",
       "             'lead': 467,\n",
       "             'based': 468,\n",
       "             'dark': 469,\n",
       "             'title': 470,\n",
       "             'oh': 471,\n",
       "             'able': 472,\n",
       "             'beginning': 473,\n",
       "             'guys': 474,\n",
       "             'already': 475,\n",
       "             'guess': 476,\n",
       "             '....': 477,\n",
       "             'care': 478,\n",
       "             'fans': 479,\n",
       "             'laugh': 480,\n",
       "             'style': 481,\n",
       "             'low': 482,\n",
       "             'worse': 483,\n",
       "             'wants': 484,\n",
       "             'despite': 485,\n",
       "             'called': 486,\n",
       "             'problem': 487,\n",
       "             'example': 488,\n",
       "             'turn': 489,\n",
       "             '3': 490,\n",
       "             'under': 491,\n",
       "             'picture': 492,\n",
       "             'entertaining': 493,\n",
       "             'turns': 494,\n",
       "             'white': 495,\n",
       "             'michael': 496,\n",
       "             'tries': 497,\n",
       "             'gave': 498,\n",
       "             'evil': 499,\n",
       "             'them.': 500,\n",
       "             'game': 501,\n",
       "             'son': 502,\n",
       "             'unfortunately': 503,\n",
       "             'behind': 504,\n",
       "             'enjoyed': 505,\n",
       "             'writing': 506,\n",
       "             'direction': 507,\n",
       "             'lives': 508,\n",
       "             'kill': 509,\n",
       "             'humor': 510,\n",
       "             '\\x96': 511,\n",
       "             'drama': 512,\n",
       "             'obviously': 513,\n",
       "             'cinema': 514,\n",
       "             'killer': 515,\n",
       "             'throughout': 516,\n",
       "             'favorite': 517,\n",
       "             'quality': 518,\n",
       "             'fine': 519,\n",
       "             'run': 520,\n",
       "             'sometimes': 521,\n",
       "             'took': 522,\n",
       "             'horrible': 523,\n",
       "             'kid': 524,\n",
       "             'starts': 525,\n",
       "             'viewer': 526,\n",
       "             'highly': 527,\n",
       "             'myself': 528,\n",
       "             'side': 529,\n",
       "             'expect': 530,\n",
       "             'matter': 531,\n",
       "             'except': 532,\n",
       "             'late': 533,\n",
       "             'heard': 534,\n",
       "             'him.': 535,\n",
       "             'girls': 536,\n",
       "             'decent': 537,\n",
       "             'parts': 538,\n",
       "             'thinking': 539,\n",
       "             'mr.': 540,\n",
       "             'amazing': 541,\n",
       "             'works': 542,\n",
       "             'says': 543,\n",
       "             'extremely': 544,\n",
       "             'group': 545,\n",
       "             'days': 546,\n",
       "             'god': 547,\n",
       "             'car': 548,\n",
       "             'directed': 549,\n",
       "             'overall': 550,\n",
       "             'history': 551,\n",
       "             'complete': 552,\n",
       "             'past': 553,\n",
       "             'wonder': 554,\n",
       "             'cannot': 555,\n",
       "             'lack': 556,\n",
       "             'brilliant': 557,\n",
       "             'act': 558,\n",
       "             'feeling': 559,\n",
       "             'soon': 560,\n",
       "             'particularly': 561,\n",
       "             'eyes': 562,\n",
       "             'killed': 563,\n",
       "             'save': 564,\n",
       "             'art': 565,\n",
       "             'town': 566,\n",
       "             'leave': 567,\n",
       "             'attempt': 568,\n",
       "             'well.': 569,\n",
       "             'including': 570,\n",
       "             'child': 571,\n",
       "             'fight': 572,\n",
       "             'wouldn': 573,\n",
       "             'stuff': 574,\n",
       "             'story.': 575,\n",
       "             'taken': 576,\n",
       "             'looked': 577,\n",
       "             'blood': 578,\n",
       "             'this.': 579,\n",
       "             '1': 580,\n",
       "             '>in': 581,\n",
       "             'actress': 582,\n",
       "             'me.': 583,\n",
       "             'close': 584,\n",
       "             'robert': 585,\n",
       "             'living': 586,\n",
       "             'police': 587,\n",
       "             'shown': 588,\n",
       "             'today': 589,\n",
       "             'heart': 590,\n",
       "             'coming': 591,\n",
       "             'hour': 592,\n",
       "             'whose': 593,\n",
       "             'david': 594,\n",
       "             'city': 595,\n",
       "             'james': 596,\n",
       "             'type': 597,\n",
       "             'one.': 598,\n",
       "             'daughter': 599,\n",
       "             '>there': 600,\n",
       "             'across': 601,\n",
       "             'hand': 602,\n",
       "             'happens': 603,\n",
       "             'exactly': 604,\n",
       "             'strong': 605,\n",
       "             'serious': 606,\n",
       "             'themselves': 607,\n",
       "             'flick': 608,\n",
       "             'stop': 609,\n",
       "             'voice': 610,\n",
       "             'huge': 611,\n",
       "             'score': 612,\n",
       "             'told': 613,\n",
       "             'opening': 614,\n",
       "             '`': 615,\n",
       "             'wish': 616,\n",
       "             'known': 617,\n",
       "             'number': 618,\n",
       "             'usually': 619,\n",
       "             '>if': 620,\n",
       "             'obvious': 621,\n",
       "             'stories': 622,\n",
       "             'involved': 623,\n",
       "             'life.': 624,\n",
       "             'moment': 625,\n",
       "             'good.': 626,\n",
       "             'saying': 627,\n",
       "             'chance': 628,\n",
       "             'please': 629,\n",
       "             'running': 630,\n",
       "             'mostly': 631,\n",
       "             'knew': 632,\n",
       "             'order': 633,\n",
       "             'slow': 634,\n",
       "             'all.': 635,\n",
       "             'genre': 636,\n",
       "             'simple': 637,\n",
       "             'call': 638,\n",
       "             'somewhat': 639,\n",
       "             'taking': 640,\n",
       "             'beyond': 641,\n",
       "             'hell': 642,\n",
       "             'song': 643,\n",
       "             'cool': 644,\n",
       "             'released': 645,\n",
       "             'major': 646,\n",
       "             'hit': 647,\n",
       "             'sad': 648,\n",
       "             'local': 649,\n",
       "             'turned': 650,\n",
       "             'husband': 651,\n",
       "             'jack': 652,\n",
       "             'brother': 653,\n",
       "             'cut': 654,\n",
       "             'started': 655,\n",
       "             'female': 656,\n",
       "             'happened': 657,\n",
       "             'age': 658,\n",
       "             'basically': 659,\n",
       "             'none': 660,\n",
       "             'murder': 661,\n",
       "             'relationship': 662,\n",
       "             'english': 663,\n",
       "             'clearly': 664,\n",
       "             'aren': 665,\n",
       "             'talking': 666,\n",
       "             'experience': 667,\n",
       "             'knows': 668,\n",
       "             'happen': 669,\n",
       "             'hero': 670,\n",
       "             'four': 671,\n",
       "             'strange': 672,\n",
       "             'apparently': 673,\n",
       "             'cinematography': 674,\n",
       "             'it.<br': 675,\n",
       "             'violence': 676,\n",
       "             'due': 677,\n",
       "             'usual': 678,\n",
       "             'jokes': 679,\n",
       "             'ends': 680,\n",
       "             'movies.': 681,\n",
       "             'upon': 682,\n",
       "             'single': 683,\n",
       "             'ok': 684,\n",
       "             'shots': 685,\n",
       "             'finds': 686,\n",
       "             'tells': 687,\n",
       "             'reality': 688,\n",
       "             'gore': 689,\n",
       "             'body': 690,\n",
       "             'roles': 691,\n",
       "             'giving': 692,\n",
       "             '5': 693,\n",
       "             'important': 694,\n",
       "             'interest': 695,\n",
       "             'haven': 696,\n",
       "             'yourself': 697,\n",
       "             'silly': 698,\n",
       "             'hours': 699,\n",
       "             'hilarious': 700,\n",
       "             'miss': 701,\n",
       "             'word': 702,\n",
       "             'documentary': 703,\n",
       "             'alone': 704,\n",
       "             'french': 705,\n",
       "             'view': 706,\n",
       "             'modern': 707,\n",
       "             'whether': 708,\n",
       "             'power': 709,\n",
       "             'supporting': 710,\n",
       "             '>but': 711,\n",
       "             'cheap': 712,\n",
       "             'british': 713,\n",
       "             'crap': 714,\n",
       "             'change': 715,\n",
       "             'musical': 716,\n",
       "             'opinion': 717,\n",
       "             'annoying': 718,\n",
       "             'king': 719,\n",
       "             'words': 720,\n",
       "             'happy': 721,\n",
       "             'events': 722,\n",
       "             'bad.': 723,\n",
       "             'falls': 724,\n",
       "             'bring': 725,\n",
       "             'george': 726,\n",
       "             'talk': 727,\n",
       "             'similar': 728,\n",
       "             'lots': 729,\n",
       "             'seriously': 730,\n",
       "             'sets': 731,\n",
       "             'light': 732,\n",
       "             'add': 733,\n",
       "             'showing': 734,\n",
       "             'ten': 735,\n",
       "             'easily': 736,\n",
       "             'certain': 737,\n",
       "             'scary': 738,\n",
       "             'ago': 739,\n",
       "             'appears': 740,\n",
       "             'needs': 741,\n",
       "             'stay': 742,\n",
       "             'talent': 743,\n",
       "             'ones': 744,\n",
       "             'possible': 745,\n",
       "             '4': 746,\n",
       "             'country': 747,\n",
       "             'career': 748,\n",
       "             'comic': 749,\n",
       "             'that.': 750,\n",
       "             'bunch': 751,\n",
       "             'five': 752,\n",
       "             'sequence': 753,\n",
       "             'team': 754,\n",
       "             'mention': 755,\n",
       "             'episodes': 756,\n",
       "             'attention': 757,\n",
       "             'romantic': 758,\n",
       "             'room': 759,\n",
       "             'here.': 760,\n",
       "             'songs': 761,\n",
       "             'space': 762,\n",
       "             'tried': 763,\n",
       "             'typical': 764,\n",
       "             'ridiculous': 765,\n",
       "             'within': 766,\n",
       "             'fall': 767,\n",
       "             'greatest': 768,\n",
       "             'novel': 769,\n",
       "             'seen.': 770,\n",
       "             'above': 771,\n",
       "             'doubt': 772,\n",
       "             'hate': 773,\n",
       "             'actual': 774,\n",
       "             'review': 775,\n",
       "             'near': 776,\n",
       "             'clear': 777,\n",
       "             'television': 778,\n",
       "             'buy': 779,\n",
       "             'kept': 780,\n",
       "             'working': 781,\n",
       "             'etc.': 782,\n",
       "             'writer': 783,\n",
       "             'problems': 784,\n",
       "             'level': 785,\n",
       "             'easy': 786,\n",
       "             'nearly': 787,\n",
       "             'among': 788,\n",
       "             'middle': 789,\n",
       "             'sorry': 790,\n",
       "             'theme': 791,\n",
       "             'enjoyable': 792,\n",
       "             'feels': 793,\n",
       "             'filmed': 794,\n",
       "             'film.<br': 795,\n",
       "             'rating': 796,\n",
       "             '$': 797,\n",
       "             'movie.<br': 798,\n",
       "             'brought': 799,\n",
       "             'using': 800,\n",
       "             '>and': 801,\n",
       "             'richard': 802,\n",
       "             '>a': 803,\n",
       "             'deal': 804,\n",
       "             'monster': 805,\n",
       "             'surprised': 806,\n",
       "             'dialog': 807,\n",
       "             'rock': 808,\n",
       "             'predictable': 809,\n",
       "             'soundtrack': 810,\n",
       "             'straight': 811,\n",
       "             'tom': 812,\n",
       "             'earth': 813,\n",
       "             'storyline': 814,\n",
       "             'imagine': 815,\n",
       "             'named': 816,\n",
       "             'means': 817,\n",
       "             'famous': 818,\n",
       "             'her.': 819,\n",
       "             'particular': 820,\n",
       "             'learn': 821,\n",
       "             'out.': 822,\n",
       "             'parents': 823,\n",
       "             'hear': 824,\n",
       "             'future': 825,\n",
       "             'subject': 826,\n",
       "             'films.': 827,\n",
       "             'gone': 828,\n",
       "             '>as': 829,\n",
       "             'lady': 830,\n",
       "             'leads': 831,\n",
       "             'peter': 832,\n",
       "             'killing': 833,\n",
       "             'end.': 834,\n",
       "             'is.': 835,\n",
       "             'moving': 836,\n",
       "             'begins': 837,\n",
       "             'sequel': 838,\n",
       "             'anyway': 839,\n",
       "             'message': 840,\n",
       "             'sister': 841,\n",
       "             'move': 842,\n",
       "             'red': 843,\n",
       "             'way.': 844,\n",
       "             'comments': 845,\n",
       "             'decided': 846,\n",
       "             'somehow': 847,\n",
       "             'viewers': 848,\n",
       "             'elements': 849,\n",
       "             'dog': 850,\n",
       "             'dull': 851,\n",
       "             'avoid': 852,\n",
       "             'sit': 853,\n",
       "             'deep': 854,\n",
       "             'general': 855,\n",
       "             'possibly': 856,\n",
       "             'theater': 857,\n",
       "             'paul': 858,\n",
       "             'editing': 859,\n",
       "             'effort': 860,\n",
       "             'entertainment': 861,\n",
       "             'fantastic': 862,\n",
       "             'check': 863,\n",
       "             'emotional': 864,\n",
       "             'became': 865,\n",
       "             'die': 866,\n",
       "             'figure': 867,\n",
       "             'realistic': 868,\n",
       "             'reviews': 869,\n",
       "             'difficult': 870,\n",
       "             'feature': 871,\n",
       "             'forget': 872,\n",
       "             'eventually': 873,\n",
       "             'tale': 874,\n",
       "             'doctor': 875,\n",
       "             'incredibly': 876,\n",
       "             'points': 877,\n",
       "             'unless': 878,\n",
       "             'rent': 879,\n",
       "             'wait': 880,\n",
       "             'write': 881,\n",
       "             'on.': 882,\n",
       "             'form': 883,\n",
       "             'poorly': 884,\n",
       "             'characters.': 885,\n",
       "             'release': 886,\n",
       "             'nor': 887,\n",
       "             'suspense': 888,\n",
       "             'leaves': 889,\n",
       "             'again.': 890,\n",
       "             'disappointed': 891,\n",
       "             'fast': 892,\n",
       "             'mystery': 893,\n",
       "             'meets': 894,\n",
       "             'reading': 895,\n",
       "             'thriller': 896,\n",
       "             'york': 897,\n",
       "             'boys': 898,\n",
       "             'animation': 899,\n",
       "             'stand': 900,\n",
       "             'atmosphere': 901,\n",
       "             'ways': 902,\n",
       "             'previous': 903,\n",
       "             'sequences': 904,\n",
       "             'too.': 905,\n",
       "             'america': 906,\n",
       "             'class': 907,\n",
       "             'funny.': 908,\n",
       "             'realize': 909,\n",
       "             'crew': 910,\n",
       "             'sexual': 911,\n",
       "             'herself': 912,\n",
       "             'keeps': 913,\n",
       "             'dance': 914,\n",
       "             'begin': 915,\n",
       "             'follow': 916,\n",
       "             'forced': 917,\n",
       "             'third': 918,\n",
       "             'whatever': 919,\n",
       "             'crime': 920,\n",
       "             'surprise': 921,\n",
       "             'meet': 922,\n",
       "             'total': 923,\n",
       "             'personal': 924,\n",
       "             'premise': 925,\n",
       "             '20': 926,\n",
       "             'japanese': 927,\n",
       "             'various': 928,\n",
       "             'okay': 929,\n",
       "             'whom': 930,\n",
       "             'minute': 931,\n",
       "             'de': 932,\n",
       "             'open': 933,\n",
       "             'viewing': 934,\n",
       "             'features': 935,\n",
       "             'needed': 936,\n",
       "             'joe': 937,\n",
       "             'plus': 938,\n",
       "             'dr.': 939,\n",
       "             'indeed': 940,\n",
       "             'weak': 941,\n",
       "             'fairly': 942,\n",
       "             'material': 943,\n",
       "             'older': 944,\n",
       "             'romance': 945,\n",
       "             'ask': 946,\n",
       "             'hot': 947,\n",
       "             'note': 948,\n",
       "             'otherwise': 949,\n",
       "             'shame': 950,\n",
       "             'towards': 951,\n",
       "             'footage': 952,\n",
       "             'memorable': 953,\n",
       "             'average': 954,\n",
       "             'imdb': 955,\n",
       "             'question': 956,\n",
       "             'cheesy': 957,\n",
       "             'eye': 958,\n",
       "             'lame': 959,\n",
       "             'oscar': 960,\n",
       "             'admit': 961,\n",
       "             'spent': 962,\n",
       "             'western': 963,\n",
       "             'inside': 964,\n",
       "             'o': 965,\n",
       "             'badly': 966,\n",
       "             'sounds': 967,\n",
       "             '80': 968,\n",
       "             'gay': 969,\n",
       "             'sci-fi': 970,\n",
       "             'disney': 971,\n",
       "             'expected': 972,\n",
       "             'lee': 973,\n",
       "             'interested': 974,\n",
       "             'male': 975,\n",
       "             'meant': 976,\n",
       "             'battle': 977,\n",
       "             'leading': 978,\n",
       "             'result': 979,\n",
       "             'street': 980,\n",
       "             'copy': 981,\n",
       "             'credits': 982,\n",
       "             'pay': 983,\n",
       "             'appear': 984,\n",
       "             'box': 985,\n",
       "             'bill': 986,\n",
       "             'creepy': 987,\n",
       "             'hands': 988,\n",
       "             'worked': 989,\n",
       "             'unique': 990,\n",
       "             'brings': 991,\n",
       "             'weird': 992,\n",
       "             'plain': 993,\n",
       "             'comment': 994,\n",
       "             'plenty': 995,\n",
       "             'front': 996,\n",
       "             'hardly': 997,\n",
       "             '>so': 998,\n",
       "             'political': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4ca5523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "194\n",
      "237\n",
      "==============================\n",
      "this\n",
      "pretty\n",
      "original\n"
     ]
    }
   ],
   "source": [
    "# string to index\n",
    "print(TEXT.vocab.stoi['this'])\n",
    "print(TEXT.vocab.stoi['pretty'])\n",
    "print(TEXT.vocab.stoi['original'])\n",
    "\n",
    "print('==='*10)\n",
    "\n",
    "# index to string\n",
    "print(TEXT.vocab.itos[14])\n",
    "print(TEXT.vocab.itos[194])\n",
    "print(TEXT.vocab.itos[237])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5480d138",
   "metadata": {},
   "source": [
    "## 버킷 이터레이터 생성\n",
    "\n",
    "- `BucketIterator` 의 주된 역할은 데이터셋에 대한 배치 구성입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4dc3ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data),     # dataset\n",
    "    sort=False,\n",
    "    repeat=False,\n",
    "    batch_size=BATCH_SIZE,       # 배치사이즈\n",
    "    device=device)               # device 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02957e30",
   "metadata": {},
   "source": [
    "1개의 배치를 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2e9d3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 batch 추출\n",
    "sample_data = next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ccc56",
   "metadata": {},
   "source": [
    "`text` 의 shape 를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "39bd7063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 120])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size, sequence_length\n",
    "sample_data.text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379ae56",
   "metadata": {},
   "source": [
    "`label` 의 shape 를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ed76fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size\n",
    "sample_data.label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fbf0fdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "        2, 1, 2, 1, 1, 1, 1, 2], device='cuda:1')"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2fa8930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1997, device='cuda:1')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.text.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37c7ff",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cac4d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress Bar 출력\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, num_classes, vocab_size, embedding_dim, hidden_size, num_layers, seq_length, drop_prob=0.1):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.num_classes = num_classes \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, \n",
    "                                      embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
    "                            hidden_size=hidden_size, \n",
    "                            num_layers=num_layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.output = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x, hidden_and_cell):\n",
    "        x = self.embedding(x)\n",
    "        output, (h, c) = self.lstm(x, hidden_and_cell)\n",
    "        h = output[:, -1, :]\n",
    "        h = h.reshape(-1, self.hidden_size)\n",
    "        h = self.dropout(h)\n",
    "#         out = self.relu(self.fc(h))\n",
    "        return self.output(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1dd9e09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (embedding): Embedding(2002, 128)\n",
       "  (lstm): LSTM(128, 256)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (output): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'num_classes': 2, \n",
    "    'vocab_size': NUM_VOCABS,\n",
    "    'embedding_dim': 128, \n",
    "    'hidden_size': 256, \n",
    "    'num_layers': 1, \n",
    "    'seq_length': 120\n",
    "}\n",
    "\n",
    "model = TextClassificationModel(**config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "75b8b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 정의: CrossEntropyLoss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "61e364a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, data_loader, loss_fn, optimizer, config, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "    \n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    counts = 0\n",
    "    \n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n",
    "    \n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for idx, data in enumerate(prograss_bar):\n",
    "        # text, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "        text = data.text.to(device)\n",
    "        label = data.label.to(device)\n",
    "        label.data.sub_(1)\n",
    "        \n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        initial_hidden = torch.zeros(config['num_layers'], config['seq_length'], config['hidden_size']).to(device)\n",
    "        initial_cell = torch.zeros(config['num_layers'], config['seq_length'], config['hidden_size']).to(device)\n",
    "        \n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = model(text, (initial_hidden, initial_cell))\n",
    "        \n",
    "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "        loss = loss_fn(output, label)\n",
    "        \n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.backward()\n",
    "        \n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "        # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "        _, pred = output.max(dim=1)\n",
    "        \n",
    "        # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "        # 합계는 corr 변수에 누적합니다.\n",
    "        corr += pred.eq(label).sum().item()\n",
    "        counts += len(label)\n",
    "        \n",
    "        # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "        # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "        running_loss += loss.item() * label.size(0)\n",
    "        \n",
    "        # 프로그레스바에 학습 상황 업데이트\n",
    "        prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}, training accuracy: {corr / counts:.5f}\")\n",
    "        \n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "    \n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8c67e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, loss_fn, config, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    \n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "        \n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for data in data_loader:\n",
    "            # text, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "            text = data.text.to(device)\n",
    "            label = data.label.to(device)\n",
    "            label.data.sub_(1)\n",
    "            \n",
    "            initial_hidden = torch.zeros(config['num_layers'], config['seq_length'], config['hidden_size']).to(device)\n",
    "            initial_cell = torch.zeros(config['num_layers'], config['seq_length'], config['hidden_size']).to(device)\n",
    "            \n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(text, (initial_hidden, initial_cell))\n",
    "            \n",
    "            # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "            _, pred = output.max(dim=1)\n",
    "            \n",
    "            # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "            # 합계는 corr 변수에 누적합니다.\n",
    "            corr += torch.sum(pred.eq(label)).item()\n",
    "            \n",
    "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "            running_loss += loss_fn(output, label).item() * label.size(0)\n",
    "        \n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader)\n",
    "        \n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "51a23461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 22.20417, training accuracy: 0.51069: 100% 1000/1000 [00:04<00:00, 223.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from inf to 22.15879. Saving Model!\n",
      "epoch 01, loss: 22.20417, acc: 0.51069, val_loss: 22.15879, val_accuracy: 16.96800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 22.08324, training accuracy: 0.53194: 100% 1000/1000 [00:04<00:00, 221.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02, loss: 22.08324, acc: 0.53194, val_loss: 22.25570, val_accuracy: 16.53200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.92497, training accuracy: 0.54166: 100% 1000/1000 [00:04<00:00, 222.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03, loss: 21.92497, acc: 0.54166, val_loss: 22.21200, val_accuracy: 16.63200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.73096, training accuracy: 0.55091: 100% 1000/1000 [00:04<00:00, 223.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04, loss: 21.73096, acc: 0.55091, val_loss: 22.32710, val_accuracy: 16.69600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.59490, training accuracy: 0.55275: 100% 1000/1000 [00:04<00:00, 224.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05, loss: 21.59490, acc: 0.55275, val_loss: 22.28215, val_accuracy: 16.99200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.46489, training accuracy: 0.55966: 100% 1000/1000 [00:04<00:00, 223.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 06, loss: 21.46489, acc: 0.55966, val_loss: 22.42038, val_accuracy: 16.72800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.36609, training accuracy: 0.56209: 100% 1000/1000 [00:04<00:00, 221.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 07, loss: 21.36609, acc: 0.56209, val_loss: 22.30847, val_accuracy: 16.79200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.29710, training accuracy: 0.56131: 100% 1000/1000 [00:04<00:00, 222.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 08, loss: 21.29710, acc: 0.56131, val_loss: 22.47132, val_accuracy: 16.75200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.23197, training accuracy: 0.56222: 100% 1000/1000 [00:04<00:00, 223.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 09, loss: 21.23197, acc: 0.56222, val_loss: 22.82309, val_accuracy: 16.66400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 21.19722, training accuracy: 0.56316: 100% 1000/1000 [00:04<00:00, 223.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 21.19722, acc: 0.56316, val_loss: 22.81967, val_accuracy: 16.66800\n"
     ]
    }
   ],
   "source": [
    "# 최대 Epoch을 지정합니다.\n",
    "num_epochs = 10\n",
    "\n",
    "# checkpoint로 저장할 모델의 이름을 정의 합니다.\n",
    "model_name = 'LSTM-Text-Classification'\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "# Epoch 별 훈련 및 검증을 수행합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    train_loss, train_acc = model_train(model, train_iterator, loss_fn, optimizer, config, device)\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = model_evaluate(model, test_iterator, loss_fn, config, device)   \n",
    "    \n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), f'{model_name}.pth')\n",
    "    \n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec3953a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e0755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
